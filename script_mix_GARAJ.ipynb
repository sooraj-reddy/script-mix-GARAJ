{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MesYMW9uErQt"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "z7WRPU7psbUt",
        "outputId": "8e1314b5-02a4-41e0-8890-72c9347950dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn_crfsuite in /usr/local/lib/python3.11/dist-packages (0.5.0)\n",
            "Requirement already satisfied: python-crfsuite>=0.9.7 in /usr/local/lib/python3.11/dist-packages (from sklearn_crfsuite) (0.9.11)\n",
            "Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from sklearn_crfsuite) (1.6.1)\n",
            "Requirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from sklearn_crfsuite) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.11/dist-packages (from sklearn_crfsuite) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install sklearn_crfsuite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tTd8C4rNcFFm",
        "outputId": "58dad7d4-062c-43b8-f66c-71a473e827b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'adapters' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!git clone https://github.com/adapter-hub/adapters.git\n",
        "!cd adapters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CUcFjhZjZPxG",
        "outputId": "ab0402df-28fa-4fdd-b42e-ce5395a7fa34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: conllu in /usr/local/lib/python3.11/dist-packages (6.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets conllu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rxhT68FmZ083",
        "outputId": "7527943e-08bd-4028-ec0f-4fb4d2f11f0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: adapters in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: transformers~=4.47.1 in /usr/local/lib/python3.11/dist-packages (from adapters) (4.47.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from adapters) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers~=4.47.1->adapters) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.47.1->adapters) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.47.1->adapters) (2.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.47.1->adapters) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.47.1->adapters) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers~=4.47.1->adapters) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.47.1->adapters) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.47.1->adapters) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.47.1->adapters) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers~=4.47.1->adapters) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers~=4.47.1->adapters) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers~=4.47.1->adapters) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers~=4.47.1->adapters) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers~=4.47.1->adapters) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers~=4.47.1->adapters) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install adapters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6w0DSzzgclYV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from adapters import AutoAdapterModel\n",
        "from transformers import AutoTokenizer\n",
        "from adapters import AdapterTrainer\n",
        "from transformers import TrainingArguments\n",
        "from transformers import AutoConfig\n",
        "from adapters import AdapterConfig\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from datasets import Dataset, concatenate_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RKXAmy01j4Uq"
      },
      "outputs": [],
      "source": [
        "%mkdir Ug/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "h99oQP5dZDvG"
      },
      "outputs": [],
      "source": [
        "import conllu\n",
        "\n",
        "def extract_corpus(conllu_path):\n",
        "    \"\"\"Extracts transliterated sentences from a CONLLU file.\"\"\"\n",
        "    translit_sentences = []\n",
        "    original_sentences = []\n",
        "    with open(conllu_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = conllu.parse(f.read())\n",
        "\n",
        "    for sentence in data:\n",
        "        original = sentence.metadata.get('text', '')\n",
        "        translit = sentence.metadata.get('translit', '')\n",
        "        if translit:\n",
        "            translit_sentences.append(translit.strip())\n",
        "        if original:\n",
        "            original_sentences.append(original.strip())\n",
        "    return original_sentences, translit_sentences\n",
        "\n",
        "def original_corpus(files):\n",
        "    corpus = {}\n",
        "    for split, file_path in files.items():\n",
        "        original, translit = extract_corpus(file_path)\n",
        "        corpus[split] = {\"original\": original, \"translit\": translit}\n",
        "\n",
        "    for split in [\"train\", \"dev\", \"test\"]:\n",
        "        with open(f\"Ug/ug_{split}_original.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(\"\\n\".join(corpus[split][\"original\"]) + \"\\n\")\n",
        "        with open(f\"Ug/ug_{split}_transliterated.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(\"\\n\".join(corpus[split][\"translit\"]) + \"\\n\")\n",
        "\n",
        "    return corpus[\"train\"][\"original\"], corpus[\"train\"][\"translit\"]\n",
        "\n",
        "files = {\n",
        "        \"train\": \"ug_udt-ud-train.conllu\",\n",
        "        \"dev\": \"ug_udt-ud-dev.conllu\",\n",
        "        \"test\": \"ug_udt-ud-test.conllu\"\n",
        "    }\n",
        "original_texts, transliterated_texts = original_corpus(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "q1sJTdVFn3wg",
        "outputId": "cc3a672b-c1a4-42f9-b7e9-5abfe5159312"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'كۆچەت ئوبدان كۆكلەۋاتقاندا، بىر كاككۈك ئۇچۇپ كېلىپ دەپتۇ:'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "original_texts[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "f33K2u3-n5C6",
        "outputId": "e50d3f1d-2a5f-4637-943a-3e2f2008f125"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'köchet obdan köklewatqanda, bir kakkük uchup këlip deptu:'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transliterated_texts[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "917404a8d9044bd2bc3ed8c78ca3f69d",
            "712c8d57806843c086b9c0ba433a5ee3",
            "8ff8f1f41ee74e968acc2d205a6f2a68",
            "e35543d225854ac3a2676d7a23677a19",
            "c566fb0af9d84f309b3ca831c1b92d46",
            "701b2e2c4adf4dd0974d22f4413341c8",
            "dbc6b2e2c25a4c219a06c378bd8fec16",
            "1efefc5bbd154c33875c76f7ccad6118",
            "b289b3eab3be46e2888b52f34438d5e6",
            "1644973841d14e5ba0de6fc82ff5263d",
            "47feb55d00304294a299114167a94359",
            "11bd99d32d99461682384dfe96cfe949",
            "e50b475a5f904497b0dae6acf50b4ef2",
            "0ef616e2d52e48fb8419dbccdc3d6233",
            "04433ca5233b4afcb8686c1c92deece2",
            "4125cdd5a52e40d392b1c802b899793c",
            "8bc20a0d3c694db6b86231098d473146",
            "42ffef1c28d446a8a5b97c31e5bded5e",
            "469df34bf36d426abde83800fdd12875",
            "e4789d4732f049f8854a3ee22d948836",
            "a0fc16461a7e44d9ba9e87c4926165e4",
            "7334fec0235545c5a49f313c78cd54ce",
            "379abd0b5d274817a9f08f8583b106e2",
            "71e431dbdfcd45c6810277eb0e2bfe43",
            "9f87ac40a8b042f48ae873176ee6052e",
            "10f8fe170f314e1188bc6471eb57b8bf",
            "127e7d98320e4f5689887020b9cf59f2",
            "12d2e85472214abda9173fe7aa06e1e5",
            "63ce9ac113ab41c6b414a5536e559513",
            "d6bef212c6e3450da477130902ef1030",
            "e638cfc18f1d4ca7bc452070b552861a",
            "8a4bb2c05be54718a3f1c2501da635c5",
            "1bc9b3aa5b8b48a886a6394b55424b17",
            "acffc7a9b4254e62b22628a323178d6d",
            "56a6c7a79329445db76c5e03e06f3e89",
            "68adacb36aa64fee877e3e7dc5585567",
            "8380346e5b844ce199917f7f47178ba8",
            "09cdbee747ca4a198a7031ceb8c917f4",
            "32a88a7cc44440898741371030fb81e3",
            "4f6761d176c4474a87c96f1dbeb6bdd0",
            "8947613023ff417e9eb3a3ca85de3273",
            "11563d3343ec4fe58b22ff40b0509fb9",
            "709fb2fb7a654422b12d1cb7409bd353",
            "c1b9be3b4e014d1dabfb3c3d08f937e5"
          ]
        },
        "id": "tJWc3K6hZOCk",
        "outputId": "0a1d398f-c8a6-4edc-e4ee-8c0660c1d42f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "917404a8d9044bd2bc3ed8c78ca3f69d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11bd99d32d99461682384dfe96cfe949",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "379abd0b5d274817a9f08f8583b106e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acffc7a9b4254e62b22628a323178d6d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "additional_tokens = [\"<new_token1>\", \"<new_token2>\"]\n",
        "tokenizer.add_tokens(additional_tokens)\n",
        "\n",
        "def tokenize(text):\n",
        "    return tokenizer(\n",
        "        text,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "u_vx7WJldedN"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, tokenizer, max_length=128):\n",
        "        self.encodings = tokenizer(\n",
        "            texts,\n",
        "            max_length=max_length,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.encodings[\"input_ids\"].shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"input_ids\": self.encodings[\"input_ids\"][idx],\n",
        "            \"attention_mask\": self.encodings[\"attention_mask\"][idx]\n",
        "        }\n",
        "\n",
        "# DataLoader\n",
        "original_dataset = TextDataset(original_texts, tokenizer)\n",
        "transliterated_dataset = TextDataset(transliterated_texts, tokenizer)\n",
        "\n",
        "original_dataloader = DataLoader(original_dataset, batch_size=16, shuffle=True)\n",
        "transliterated_dataloader = DataLoader(transliterated_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# MLM Components\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=True,\n",
        "    mlm_probability=0.15\n",
        ")\n",
        "mlm_loss = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7Qg1my2Eyls"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347,
          "referenced_widgets": [
            "481da10d40834609aaff9729d6a238cb",
            "cadf26b364424441adf92e52550ddd6a",
            "4026c33ee5234cba8b807ab18f49cd37",
            "7180d8c8834e4ead9038b912f2c89c78",
            "3a316ceac9c14cb79e2a05323e9a77cd",
            "3c95366915ee4dae97ff6aecd472a4f7",
            "85285f8ab6c147c8a6e4a3293a501122",
            "9db173de3bbd408a8061ec9a6a14ff37",
            "eaa9e4898dc147deb3924097d73a478d",
            "204139dc12fd4e6fa2a12e8b0747df99",
            "b36a988efe2e496fa0355dd809993764"
          ]
        },
        "id": "X84LR5ioBokv",
        "outputId": "8f309e7e-4548-4216-8ad8-f7a00bbb5142"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "481da10d40834609aaff9729d6a238cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertAdapterModel were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['heads.default.3.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-13-2db71812f340>:33: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "<ipython-input-13-2db71812f340>:63: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Loss: 5.1926\n",
            "Epoch 2 | Loss: 4.6305\n",
            "Epoch 3 | Loss: 4.7053\n",
            "Epoch 4 | Loss: 5.1842\n",
            "Epoch 5 | Loss: 3.9855\n",
            "Epoch 1 | Loss: 6.5837\n",
            "Epoch 2 | Loss: 6.0928\n",
            "Epoch 3 | Loss: 6.5337\n",
            "Epoch 4 | Loss: 7.0732\n",
            "Epoch 5 | Loss: 6.7741\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from adapters import AutoAdapterModel, Stack, AdapterConfig\n",
        "from transformers import DataCollatorForLanguageModeling, AutoTokenizer\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import LinearLR\n",
        "\n",
        "# Model Initialization\n",
        "model = AutoAdapterModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "# Adapter Configuration\n",
        "model.freeze_model()\n",
        "\n",
        "# Add adapters\n",
        "lang_config = AdapterConfig.load(\n",
        "    \"pfeiffer\",\n",
        "    reduction_factor=16,\n",
        "    leave_out=[11]\n",
        ")\n",
        "model.add_adapter(\"la_s\", config=lang_config)\n",
        "model.add_adapter(\"la_t\", config=lang_config)\n",
        "\n",
        "\n",
        "for param in model.heads.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    if \"adapter\" not in name:\n",
        "        assert not param.requires_grad, f\"Base param {name} is trainable!\"\n",
        "\n",
        "# Training Setup\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "\n",
        "def train_adapter(adapter_name, dataloader, num_epochs=1):\n",
        "    model.train_adapter(adapter_name)\n",
        "    model.set_active_adapters(Stack(adapter_name))\n",
        "    optimizer = AdamW(\n",
        "        model.parameters(),\n",
        "        lr=1e-4,\n",
        "        weight_decay=0.01\n",
        "    )\n",
        "\n",
        "    scheduler = LinearLR(\n",
        "        optimizer,\n",
        "        start_factor=0.3,\n",
        "        total_iters=len(dataloader)*num_epochs//4\n",
        "    )\n",
        "\n",
        "    accumulation_steps = 4\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "\n",
        "        for i, batch in enumerate(dataloader):\n",
        "            with torch.cuda.amp.autocast():\n",
        "                masked_inputs = data_collator([{\"input_ids\": ids} for ids in batch[\"input_ids\"]])\n",
        "\n",
        "                outputs = model(\n",
        "                    input_ids=masked_inputs[\"input_ids\"],\n",
        "                    attention_mask=masked_inputs[\"attention_mask\"]\n",
        "                )\n",
        "\n",
        "                loss = torch.nn.CrossEntropyLoss(ignore_index=-100)(\n",
        "                    outputs.logits.view(-1, tokenizer.vocab_size),\n",
        "                    masked_inputs[\"labels\"].view(-1)\n",
        "                )\n",
        "                loss = loss / accumulation_steps\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            if (i + 1) % accumulation_steps == 0:\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad()\n",
        "                scheduler.step()\n",
        "\n",
        "        eval_loss = evaluate_mlm(dataloader)\n",
        "        print(f\"Epoch {epoch+1} | Loss: {eval_loss:.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_mlm(dataloader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            masked_inputs = data_collator([{\"input_ids\": ids} for ids in batch[\"input_ids\"]])\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=masked_inputs[\"input_ids\"],\n",
        "                attention_mask=masked_inputs[\"attention_mask\"]\n",
        "            )\n",
        "\n",
        "            loss = torch.nn.CrossEntropyLoss(ignore_index=-100)(\n",
        "                outputs.logits.view(-1, tokenizer.vocab_size),\n",
        "                masked_inputs[\"labels\"].view(-1)\n",
        "            )\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "# Train la_s\n",
        "train_adapter(\"la_s\", original_dataloader, 5)\n",
        "\n",
        "# Train la_t\n",
        "train_adapter(\"la_t\", transliterated_dataloader, 5)\n",
        "\n",
        "model.save_adapter(\"./la_s\", \"la_s\", with_head=False)\n",
        "model.save_adapter(\"./la_t\", \"la_t\", with_head=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uY2_IddqhLrF",
        "outputId": "54cfa9c5-c294-4f86-b1f8-4f672beb7827"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "la_s config: {0: {'output_adapter': Adapter(\n",
            "  (non_linearity): Activation_Function_Class(\n",
            "    (f): ReLU()\n",
            "  )\n",
            "  (adapter_down): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "    (1): Activation_Function_Class(\n",
            "      (f): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            ")}, 1: {'output_adapter': Adapter(\n",
            "  (non_linearity): Activation_Function_Class(\n",
            "    (f): ReLU()\n",
            "  )\n",
            "  (adapter_down): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "    (1): Activation_Function_Class(\n",
            "      (f): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            ")}, 2: {'output_adapter': Adapter(\n",
            "  (non_linearity): Activation_Function_Class(\n",
            "    (f): ReLU()\n",
            "  )\n",
            "  (adapter_down): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "    (1): Activation_Function_Class(\n",
            "      (f): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            ")}, 3: {'output_adapter': Adapter(\n",
            "  (non_linearity): Activation_Function_Class(\n",
            "    (f): ReLU()\n",
            "  )\n",
            "  (adapter_down): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "    (1): Activation_Function_Class(\n",
            "      (f): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            ")}, 4: {'output_adapter': Adapter(\n",
            "  (non_linearity): Activation_Function_Class(\n",
            "    (f): ReLU()\n",
            "  )\n",
            "  (adapter_down): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "    (1): Activation_Function_Class(\n",
            "      (f): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            ")}, 5: {'output_adapter': Adapter(\n",
            "  (non_linearity): Activation_Function_Class(\n",
            "    (f): ReLU()\n",
            "  )\n",
            "  (adapter_down): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "    (1): Activation_Function_Class(\n",
            "      (f): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            ")}, 6: {'output_adapter': Adapter(\n",
            "  (non_linearity): Activation_Function_Class(\n",
            "    (f): ReLU()\n",
            "  )\n",
            "  (adapter_down): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "    (1): Activation_Function_Class(\n",
            "      (f): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            ")}, 7: {'output_adapter': Adapter(\n",
            "  (non_linearity): Activation_Function_Class(\n",
            "    (f): ReLU()\n",
            "  )\n",
            "  (adapter_down): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "    (1): Activation_Function_Class(\n",
            "      (f): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            ")}, 8: {'output_adapter': Adapter(\n",
            "  (non_linearity): Activation_Function_Class(\n",
            "    (f): ReLU()\n",
            "  )\n",
            "  (adapter_down): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "    (1): Activation_Function_Class(\n",
            "      (f): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            ")}, 9: {'output_adapter': Adapter(\n",
            "  (non_linearity): Activation_Function_Class(\n",
            "    (f): ReLU()\n",
            "  )\n",
            "  (adapter_down): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "    (1): Activation_Function_Class(\n",
            "      (f): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            ")}, 10: {'output_adapter': Adapter(\n",
            "  (non_linearity): Activation_Function_Class(\n",
            "    (f): ReLU()\n",
            "  )\n",
            "  (adapter_down): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "    (1): Activation_Function_Class(\n",
            "      (f): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            ")}}\n",
            "la_t config: {0: {'output_adapter': Adapter(\n",
            "  (non_linearity): Activation_Function_Class(\n",
            "    (f): ReLU()\n",
            "  )\n",
            "  (adapter_down): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "    (1): Activation_Function_Class(\n",
            "      (f): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            ")}, 1: {'output_adapter': Adapter(\n",
            "  (non_linearity): Activation_Function_Class(\n",
            "    (f): ReLU()\n",
            "  )\n",
            "  (adapter_down): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "    (1): Activation_Function_Class(\n",
            "      (f): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            ")}, 2: {'output_adapter': Adapter(\n",
            "  (non_linearity): Activation_Function_Class(\n",
            "    (f): ReLU()\n",
            "  )\n",
            "  (adapter_down): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "    (1): Activation_Function_Class(\n",
            "      (f): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            ")}, 3: {'output_adapter': Adapter(\n",
            "  (non_linearity): Activation_Function_Class(\n",
            "    (f): ReLU()\n",
            "  )\n",
            "  (adapter_down): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "    (1): Activation_Function_Class(\n",
            "      (f): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            ")}, 4: {'output_adapter': Adapter(\n",
            "  (non_linearity): Activation_Function_Class(\n",
            "    (f): ReLU()\n",
            "  )\n",
            "  (adapter_down): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "    (1): Activation_Function_Class(\n",
            "      (f): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            ")}, 5: {'output_adapter': Adapter(\n",
            "  (non_linearity): Activation_Function_Class(\n",
            "    (f): ReLU()\n",
            "  )\n",
            "  (adapter_down): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "    (1): Activation_Function_Class(\n",
            "      (f): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            ")}, 6: {'output_adapter': Adapter(\n",
            "  (non_linearity): Activation_Function_Class(\n",
            "    (f): ReLU()\n",
            "  )\n",
            "  (adapter_down): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "    (1): Activation_Function_Class(\n",
            "      (f): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            ")}, 7: {'output_adapter': Adapter(\n",
            "  (non_linearity): Activation_Function_Class(\n",
            "    (f): ReLU()\n",
            "  )\n",
            "  (adapter_down): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "    (1): Activation_Function_Class(\n",
            "      (f): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            ")}, 8: {'output_adapter': Adapter(\n",
            "  (non_linearity): Activation_Function_Class(\n",
            "    (f): ReLU()\n",
            "  )\n",
            "  (adapter_down): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "    (1): Activation_Function_Class(\n",
            "      (f): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            ")}, 9: {'output_adapter': Adapter(\n",
            "  (non_linearity): Activation_Function_Class(\n",
            "    (f): ReLU()\n",
            "  )\n",
            "  (adapter_down): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "    (1): Activation_Function_Class(\n",
            "      (f): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            ")}, 10: {'output_adapter': Adapter(\n",
            "  (non_linearity): Activation_Function_Class(\n",
            "    (f): ReLU()\n",
            "  )\n",
            "  (adapter_down): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=48, bias=True)\n",
            "    (1): Activation_Function_Class(\n",
            "      (f): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            ")}}\n"
          ]
        }
      ],
      "source": [
        "#  adapter configurations\n",
        "print(\"\\nla_s config:\", model.get_adapter(\"la_s\"))\n",
        "print(\"la_t config:\", model.get_adapter(\"la_t\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibPyICDzgQC9",
        "outputId": "002cac3a-d659-4da1-9036-72813b6fa29c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Stack[la_t]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.active_adapters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0SiG5QUg7Fq",
        "outputId": "5924107c-a888-4bfc-d504-f0755640f12f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Active adapters: Stack[la_t]\n"
          ]
        }
      ],
      "source": [
        "# currently active adapters\n",
        "print(\"Active adapters:\", model.active_adapters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tGbQWhGEAIBL"
      },
      "outputs": [],
      "source": [
        "SFE_MODEL = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "C5AaW5RQAHqZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgcyE8nqjI0k",
        "outputId": "5ade50c9-e597-4d65-c9cc-28eeb8900481"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original_tokens: ['[CLS]', '[UNK]', '[UNK]', 'ي', '##ى', '##لد', '##ا', '،', '[UNK]', 'ت', '##ۆ', '##ت', 'ي', '##ى', '##لد', '##ا', '[UNK]', '[UNK]', '[UNK]', 'ئ', '##ا', '##ڭ', '##لى', '##مى', '##غان', '##مى', '##دى', '##ڭ', '؟', '[SEP]']\n",
            "predicted_tokens: ['[CLS]', '[UNK]', '[UNK]', 'ي', '##ى', '##لد', '##ا', '،', '[UNK]', 'ت', '##ۆ', '##ت', 'ي', '##ى', '##لد', '##ا', '[UNK]', '[UNK]', '[UNK]', 'ئ', '##ا', '##ڭ', '##لى', '##مى', '##غان', '##مى', '##دى', '##ڭ', '؟', '[SEP]']\n",
            "original_text: [CLS] [UNK] [UNK] يىلدا ، [UNK] تۆت يىلدا [UNK] [UNK] [UNK] ئاڭلىمىغانمىدىڭ ؟ [SEP]\n",
            "predicted_text: [CLS] [UNK] [UNK] يىلدا ، [UNK] تۆت يىلدا [UNK] [UNK] [UNK] ئاڭلىمىغانمىدىڭ ؟ [SEP]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "def test_mlm_with_adapter(text, adapter_name=None):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "    input_ids = inputs[\"input_ids\"].clone()\n",
        "    attention_mask = inputs[\"attention_mask\"].clone()\n",
        "    masked_indices = (input_ids == tokenizer.mask_token_id).nonzero(as_tuple=True)[1]\n",
        "    if adapter_name:\n",
        "        model.set_active_adapters(Stack(adapter_name))\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "    for idx in masked_indices:\n",
        "        predicted_token_id = torch.argmax(outputs.logits[0, idx], dim=-1).item()\n",
        "        input_ids[0, idx] = predicted_token_id\n",
        "\n",
        "    original_tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze().tolist())\n",
        "    predicted_tokens = tokenizer.convert_ids_to_tokens(input_ids.squeeze().tolist())\n",
        "\n",
        "    original_text = tokenizer.convert_tokens_to_string(original_tokens)\n",
        "    predicted_text = tokenizer.convert_tokens_to_string(predicted_tokens)\n",
        "\n",
        "    return {\n",
        "        \"original_tokens\": original_tokens,\n",
        "        \"predicted_tokens\": predicted_tokens,\n",
        "        \"original_text\": original_text,\n",
        "        \"predicted_text\": predicted_text\n",
        "    }\n",
        "\n",
        "test_text = \"نەشپۈت بەش يىلدا ، ئۆرۈك تۆت يىلدا مېۋە بېرىدۇ دېگەننى ئاڭلىمىغانمىدىڭ ؟\"\n",
        "result = test_mlm_with_adapter(test_text, \"la_s\")\n",
        "\n",
        "print(\"original_tokens:\", result[\"original_tokens\"])\n",
        "print(\"predicted_tokens:\", result[\"predicted_tokens\"])\n",
        "print(\"original_text:\", result[\"original_text\"])\n",
        "print(\"predicted_text:\", result[\"predicted_text\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88e9EPDLo5Ya"
      },
      "source": [
        "## AdapterFusionPLus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "uGhMKFxgZsCn"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "class AdapterFusionPlus(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2 * hidden_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, 2)\n",
        "        )\n",
        "    def forward(self, outputs_s, outputs_t):\n",
        "        combined = torch.cat([outputs_s, outputs_t], dim=-1)  # [B, T, 2*H]\n",
        "        raw_weights = self.mlp(combined)                      # [B, T, 2]\n",
        "        weights = torch.softmax(raw_weights, dim=-1)          # [B, T, 2]\n",
        "\n",
        "        w_s = weights[:, :, 0].unsqueeze(-1)  # [B, T, 1]\n",
        "        w_t = weights[:, :, 1].unsqueeze(-1)  # [B, T, 1]\n",
        "\n",
        "        fused_output = w_s * outputs_s + w_t * outputs_t      # [B, T, H]\n",
        "        return fused_output\n",
        "\n",
        "fusion_layer = AdapterFusionPlus(model.config.hidden_size)\n",
        "\n",
        "def forward_with_fusion(input_ids):\n",
        "    outputs_s = model(input_ids, adapter_names=\"la_s\")\n",
        "    outputs_t = model(input_ids, adapter_names=\"la_t\")\n",
        "    fused_output = fusion_layer(outputs_s.last_hidden_state, outputs_t.last_hidden_state)\n",
        "    return fused_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAAIa9wXX0Oo"
      },
      "source": [
        "## POS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJ0ATeGHX1Y3",
        "outputId": "a9978a28-da9d-42db-88d0-8e4141e81c8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of POS tags: 15\n",
            "{'NOUN': 0, 'PUNCT': 1, 'VERB': 2, 'PRON': 3, 'NUM': 4, 'ADJ': 5, 'ADV': 6, 'PROPN': 7, 'INTJ': 8, 'AUX': 9, 'CCONJ': 10, 'ADP': 11, 'PART': 12, '[PAD]': 13, '[UNK]': 14}\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import re\n",
        "from transformers import AutoModelForTokenClassification, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn_crfsuite import CRF, metrics\n",
        "from conllu import parse_incr\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import defaultdict\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "def build_pos_vocab(conllu_data_path):\n",
        "    pos_vocab = defaultdict(int)\n",
        "\n",
        "    with open(conllu_data_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            if line.startswith(\"#\") or not line.strip():\n",
        "                continue\n",
        "\n",
        "            parts = line.strip().split(\"\\t\")\n",
        "\n",
        "            if \"-\" in parts[0]:\n",
        "                continue\n",
        "            pos_tag = parts[3]\n",
        "            pos_vocab[pos_tag] += 1\n",
        "\n",
        "    pos_vocab[\"[PAD]\"] = 0  # For padding\n",
        "    pos_vocab[\"[UNK]\"] = 0  # For unknown tags\n",
        "\n",
        "    return pos_vocab\n",
        "\n",
        "\n",
        "conllu_pth = 'ug_udt-ud-train.conllu'\n",
        "\n",
        "all_pos_tags = []\n",
        "with open(conllu_pth, \"r\") as f:\n",
        "    for line in f:\n",
        "        if line.startswith(\"#\") or not line.strip():\n",
        "            continue\n",
        "        parts = line.strip().split(\"\\t\")\n",
        "        if \"-\" in parts[0]:\n",
        "            continue\n",
        "        all_pos_tags.append(parts[3])  # or parts[4]\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(all_pos_tags + [\"[PAD]\", \"[UNK]\"])\n",
        "\n",
        "num_pos_tags = len(le.classes_)\n",
        "\n",
        "pos_vocab = build_pos_vocab(conllu_pth)\n",
        "num_pos_tags = len(pos_vocab)\n",
        "print(f\"Number of POS tags: {num_pos_tags}\")\n",
        "\n",
        "sorted_tags = sorted(\n",
        "    [tag for tag in pos_vocab.keys() if tag not in [\"[PAD]\", \"[UNK]\"]],\n",
        "    key=lambda x: pos_vocab[x],\n",
        "    reverse=True\n",
        ")\n",
        "\n",
        "sorted_tags += [\"[PAD]\", \"[UNK]\"]\n",
        "\n",
        "#  label2id mapping\n",
        "pos_label2id = {tag: idx for idx, tag in enumerate(sorted_tags)}\n",
        "id2pos_label = {idx: tag for tag, idx in pos_label2id.items()}\n",
        "\n",
        "print(pos_label2id)\n",
        "\n",
        "\n",
        "def load_conllu_data(file_path):\n",
        "    \"\"\"Loads CoNLL-U formatted data and extracts sentences with POS tags.\"\"\"\n",
        "    data_file = open(file_path, \"r\", encoding=\"utf-8\")\n",
        "    ud_treebank = []\n",
        "\n",
        "    for tokenlist in parse_incr(data_file):\n",
        "        tokens, tags = [], []\n",
        "        for token in tokenlist:\n",
        "            tokens.append(token[\"form\"])\n",
        "            tags.append(token[\"upostag\"])\n",
        "        ud_treebank.append((tokens, tags))\n",
        "\n",
        "    return ud_treebank\n",
        "\n",
        "conllu_pth = 'ug_udt-ud-train.conllu'\n",
        "ud_treebank = load_conllu_data(conllu_pth)\n",
        "\n",
        "\n",
        "def extract_features(sentence, index):\n",
        "    \"\"\"Extracts linguistic features from a given sentence at a specific index.\"\"\"\n",
        "    return {\n",
        "        'word': sentence[index],\n",
        "        'is_first': index == 0,\n",
        "        'is_last': index == len(sentence) - 1,\n",
        "        'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
        "        'is_all_caps': sentence[index].upper() == sentence[index],\n",
        "        'is_all_lower': sentence[index].lower() == sentence[index],\n",
        "        'is_alphanumeric': bool(re.match(r'^(?=.*[0-9]$)(?=.*[a-zA-Z])', sentence[index])),\n",
        "        'prefix-1': sentence[index][0],\n",
        "        'prefix-2': sentence[index][:2],\n",
        "        'prefix-3': sentence[index][:3],\n",
        "        'suffix-1': sentence[index][-1],\n",
        "        'suffix-2': sentence[index][-2:],\n",
        "        'suffix-3': sentence[index][-3:],\n",
        "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
        "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
        "        'has_hyphen': '-' in sentence[index],\n",
        "        'is_numeric': sentence[index].isdigit(),\n",
        "    }\n",
        "\n",
        "def transform_to_dataset(tagged_sentences):\n",
        "    \"\"\"Transforms tokenized sentences into feature sets and corresponding labels.\"\"\"\n",
        "    X, y = [], []\n",
        "    for sentence, tags in tagged_sentences:\n",
        "        X.append([extract_features(sentence, i) for i in range(len(sentence))])\n",
        "        y.append(tags)\n",
        "    return X, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSa9kPUMX28l",
        "outputId": "4459b233-39a3-42fd-b4c3-5fa7e1ef72f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: نەشپۈت بەش يىلدا ، ئۆرۈك تۆت يىلدا مېۋە بېرىدۇ دېگەننى ئاڭلىمىغانمىدىڭ ؟\n",
            "Labels: ['NOUN', 'NUM', 'NOUN', 'PUNCT', 'NOUN', 'NUM', 'NOUN', 'NOUN', 'VERB', 'VERB', 'VERB', 'PUNCT']\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "class POSDataset(Dataset):\n",
        "    \"\"\"Custom dataset for POS tagging with BERT tokenizer.\"\"\"\n",
        "    def __init__(self, ud_treebank, tokenizer, max_length=128):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.features = []\n",
        "        self.labels = []\n",
        "        self.sentences = []\n",
        "\n",
        "        all_tags = {tag for _, tags in ud_treebank for tag in tags}\n",
        "        self.label_map = {tag: i for i, tag in enumerate(sorted(all_tags))}\n",
        "        self.id2label = {i: tag for tag, i in self.label_map.items()}\n",
        "\n",
        "        for tokens, tags in ud_treebank:\n",
        "            self.sentences.append(tokens)\n",
        "            inputs = tokenizer(\n",
        "                tokens,\n",
        "                is_split_into_words=True,\n",
        "                padding=\"max_length\",\n",
        "                truncation=True,\n",
        "                max_length=max_length,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "\n",
        "            word_ids = inputs.word_ids()\n",
        "            previous_word_id = None\n",
        "            label_ids = []\n",
        "\n",
        "            for word_id in word_ids:\n",
        "                if word_id is None:\n",
        "                    label_ids.append(-100)\n",
        "                elif word_id != previous_word_id:\n",
        "                    label_ids.append(self.label_map[tags[word_id]])\n",
        "                else:\n",
        "                    label_ids.append(-100)\n",
        "                previous_word_id = word_id\n",
        "\n",
        "            self.features.append({k: v.squeeze(0) for k, v in inputs.items()})\n",
        "            self.labels.append(torch.tensor(label_ids))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = self.sentences[idx]\n",
        "        readable_labels = [self.id2label[label.item()] for label in self.labels[idx] if label.item() != -100]\n",
        "\n",
        "        return {\n",
        "            \"sentence\": sentence,\n",
        "            \"input_ids\": self.features[idx][\"input_ids\"],\n",
        "            \"attention_mask\": self.features[idx][\"attention_mask\"],\n",
        "            \"labels_readable\": readable_labels,\n",
        "            \"labels\": self.labels[idx]\n",
        "        }\n",
        "\n",
        "dataset = POSDataset(ud_treebank, tokenizer)\n",
        "\n",
        "sample = dataset[0]\n",
        "print(\"Sentence:\", \" \".join(sample[\"sentence\"]))\n",
        "print(\"Labels:\", sample[\"labels_readable\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkT30c1oYGFB"
      },
      "source": [
        "## POS USING AdapterFusionPlus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "54cc435VX5Ta",
        "outputId": "244e4a30-7648-4c94-9726-4148bffa4943"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15 - Loss: 2.3302\n",
            "Epoch 2/15 - Loss: 1.9530\n",
            "Epoch 3/15 - Loss: 1.7612\n",
            "Epoch 4/15 - Loss: 1.6558\n",
            "Epoch 5/15 - Loss: 1.5756\n",
            "Epoch 6/15 - Loss: 1.5216\n",
            "Epoch 7/15 - Loss: 1.4770\n",
            "Epoch 8/15 - Loss: 1.4215\n",
            "Epoch 9/15 - Loss: 1.3773\n",
            "Epoch 10/15 - Loss: 1.3355\n",
            "Epoch 11/15 - Loss: 1.3042\n",
            "Epoch 12/15 - Loss: 1.2700\n",
            "Epoch 13/15 - Loss: 1.2301\n",
            "Epoch 14/15 - Loss: 1.2147\n",
            "Epoch 15/15 - Loss: 1.1782\n",
            "POS Tagging Accuracy: 0.3319\n"
          ]
        }
      ],
      "source": [
        "class POSClassifier(nn.Module):\n",
        "    \"\"\"Final classifier for POS tagging.\"\"\"\n",
        "    def __init__(self, hidden_size, num_labels):\n",
        "        super().__init__()\n",
        "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, fused_output):\n",
        "        return self.classifier(fused_output)\n",
        "\n",
        "class POSFusionModel(nn.Module):\n",
        "    \"\"\"POS tagging model with AdapterFusion+.\"\"\"\n",
        "    def __init__(self, base_model, fusion_layer, classifier):\n",
        "        super().__init__()\n",
        "        self.base_model = base_model\n",
        "        self.fusion_layer = fusion_layer\n",
        "        self.classifier = classifier\n",
        "        self.base_model.config.output_hidden_states = True\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs_s = self.base_model(input_ids=input_ids, attention_mask=attention_mask, adapter_names=\"la_s\")\n",
        "        outputs_t = self.base_model(input_ids=input_ids, attention_mask=attention_mask, adapter_names=\"la_t\")\n",
        "        fused = self.fusion_layer(outputs_s.hidden_states[-1], outputs_t.hidden_states[-1])\n",
        "        return self.classifier(fused)\n",
        "\n",
        "\n",
        "def train_pos_model(model, dataloader, num_epochs=3, lr=1e-4):\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for batch in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            input_ids, attention_mask, labels = batch[\"input_ids\"].cuda(), batch[\"attention_mask\"].cuda(), batch[\"labels\"].cuda()\n",
        "\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            loss = criterion(logits.view(-1, logits.shape[-1]), labels.view(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {total_loss / len(dataloader):.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_pos_model(model, dataloader):\n",
        "    model.eval()\n",
        "    total_correct, total_tokens = 0, 0\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids, attention_mask, labels = (\n",
        "                batch[\"input_ids\"].cuda(),\n",
        "                batch[\"attention_mask\"].cuda(),\n",
        "                batch[\"labels\"].cuda(),\n",
        "            )\n",
        "\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            predictions = torch.argmax(logits, dim=-1)\n",
        "            # print(\"labels\",labels )\n",
        "            # print(\"predictions\", predictions)\n",
        "            mask = labels != -100\n",
        "            correct = (predictions == labels) & mask\n",
        "            total_correct += correct.sum().item()\n",
        "            total_tokens += mask.sum().item()\n",
        "            y_true.extend(labels[mask].cpu().numpy().tolist())\n",
        "            y_pred.extend(predictions[mask].cpu().numpy().tolist())\n",
        "\n",
        "    print(f\"POS Tagging Accuracy: {total_correct / total_tokens:.4f}\")\n",
        "    return y_true, y_pred\n",
        "\n",
        "def collate_fn(batch):\n",
        "    input_ids = [item[\"input_ids\"] for item in batch]\n",
        "    attention_mask = [item[\"attention_mask\"] for item in batch]\n",
        "    labels = [item[\"labels\"] for item in batch]\n",
        "\n",
        "    input_ids = torch.nn.utils.rnn.pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "    attention_mask = torch.nn.utils.rnn.pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
        "    labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=-100)\n",
        "\n",
        "    return {\"input_ids\": input_ids.cuda(), \"attention_mask\": attention_mask.cuda(), \"labels\": labels.cuda()}\n",
        "\n",
        "train_dataset = POSDataset(load_conllu_data(conllu_pth), tokenizer)\n",
        "test_dataset = POSDataset(load_conllu_data(\"ug_udt-ud-test.conllu\"), tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "fusion_layer = AdapterFusionPlus(768).cuda()\n",
        "pos_classifier = POSClassifier(768, len(train_dataset.label_map)).cuda()\n",
        "model1 = model\n",
        "pos_model = POSFusionModel(model1, fusion_layer, pos_classifier).cuda()\n",
        "\n",
        "train_pos_model(pos_model, train_loader, num_epochs=15)\n",
        "y_true, y_pred = evaluate_pos_model(pos_model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzrUcdLbX_ww",
        "outputId": "8d113313-85d3-4b45-c7b5-dbb073b45f36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('نەشپۈت', 'ADP'), ('بەش', 'ADV'), ('يىلدا،', 'ADV'), ('ئۆرۈك', 'ADV'), ('تۆت', 'ADV'), ('يىلدا', 'ADV'), ('مېۋە', 'ADV'), ('بېرىدۇ', 'ADP'), ('دېگەننى', 'ADV'), ('ئاڭلىمىغانمىدىڭ؟', 'ADV')]\n"
          ]
        }
      ],
      "source": [
        "def predict_pos(sentence):\n",
        "    inputs = tokenizer(sentence.split(), is_split_into_words=True, padding=\"max_length\", truncation=True, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = pos_model(inputs[\"input_ids\"], inputs[\"attention_mask\"])\n",
        "\n",
        "    predictions = torch.argmax(logits, dim=-1).squeeze().tolist()\n",
        "    pred_labels = [id2pos_label[i] for i in predictions if i != -100]\n",
        "\n",
        "    return list(zip(sentence.split(), pred_labels))\n",
        "\n",
        "\n",
        "test_sentence = \"نەشپۈت بەش يىلدا، ئۆرۈك تۆت يىلدا مېۋە بېرىدۇ دېگەننى ئاڭلىمىغانمىدىڭ؟\"\n",
        "# test_sentence = \"neshpüt besh yilda, örük töt yilda mëwe bëridu dëgenni anglimighanmiding?\"\n",
        "print(predict_pos(test_sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bIGaV5KYCd2",
        "outputId": "3721a852-22ce-479b-bb88-7407c2463a57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## AdapterFusion Model Evaluation ##\n",
            "F1 score on Dev Data: 0.23745444350995232\n",
            "\n",
            "Class-wise scores:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ADJ       0.00      0.00      0.00        15\n",
            "         ADP       0.00      0.00      0.00         9\n",
            "         ADV       0.00      0.00      0.00         7\n",
            "         AUX       0.00      0.00      0.00         7\n",
            "       CCONJ       0.00      0.00      0.00         4\n",
            "        INTJ       0.00      0.00      0.00         2\n",
            "        NOUN       0.49      0.88      0.63        88\n",
            "         NUM       0.00      0.00      0.00         4\n",
            "        PART       0.00      0.00      0.00        12\n",
            "        PRON       0.00      0.00      0.00        39\n",
            "       PROPN       0.00      0.00      0.00        45\n",
            "       PUNCT       0.00      0.00      0.00         0\n",
            "        VERB       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.33       232\n",
            "   macro avg       0.04      0.07      0.05       232\n",
            "weighted avg       0.18      0.33      0.24       232\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "print(\"## AdapterFusion Model Evaluation ##\")\n",
        "\n",
        "f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
        "print(\"F1 score on Dev Data:\", f1)\n",
        "\n",
        "print(\"\\nClass-wise scores:\")\n",
        "print(classification_report(y_true, y_pred, target_names=train_dataset.label_map.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjfnP0X7YMVJ"
      },
      "source": [
        "## POS USING AdapterFusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGpIKxQbYPdq"
      },
      "outputs": [],
      "source": [
        "from adapters.composition import Fuse\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
        "\n",
        "train_data = load_conllu_data(conllu_pth)\n",
        "dev_data = load_conllu_data(\"ug_udt-ud-test.conllu\")\n",
        "\n",
        "# POS label mapping\n",
        "all_tags = sorted({tag for _, tags in train_data+dev_data for tag in tags})\n",
        "id2label = {i: tag for i, tag in enumerate(all_tags)}\n",
        "label2id = {tag: i for i, tag in id2label.items()}\n",
        "\n",
        "# Tokenization and Dataset\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "train_dataset = POSDataset(train_data, tokenizer)\n",
        "dev_dataset = POSDataset(dev_data, tokenizer)\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions = np.argmax(p.predictions, axis=2)\n",
        "    true_labels = p.label_ids\n",
        "    mask = true_labels != -100\n",
        "    y_true = true_labels[mask].flatten()\n",
        "    y_pred = predictions[mask].flatten()\n",
        "\n",
        "    return {\n",
        "        \"f1\": f1_score(y_true, y_pred, average=\"weighted\"),\n",
        "        \"accuracy\": accuracy_score(y_true, y_pred)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 999
        },
        "id": "xZzDGBShYR_j",
        "outputId": "3d162c11-a847-4e1c-934a-40b45af28b16"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertAdapterModel were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['heads.default.3.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgarimat\u001b[0m (\u001b[33mgarimat-indian-institute-of-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250327_092709-1kj5kcf2</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/garimat-indian-institute-of-technology/huggingface/runs/1kj5kcf2' target=\"_blank\">./pos_fusion</a></strong> to <a href='https://wandb.ai/garimat-indian-institute-of-technology/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/garimat-indian-institute-of-technology/huggingface' target=\"_blank\">https://wandb.ai/garimat-indian-institute-of-technology/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/garimat-indian-institute-of-technology/huggingface/runs/1kj5kcf2' target=\"_blank\">https://wandb.ai/garimat-indian-institute-of-technology/huggingface/runs/1kj5kcf2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [160/160 01:31, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.638740</td>\n",
              "      <td>0.211462</td>\n",
              "      <td>0.344828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.833968</td>\n",
              "      <td>0.223766</td>\n",
              "      <td>0.353448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.803625</td>\n",
              "      <td>0.237575</td>\n",
              "      <td>0.379310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.806741</td>\n",
              "      <td>0.228702</td>\n",
              "      <td>0.353448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.836170</td>\n",
              "      <td>0.234743</td>\n",
              "      <td>0.353448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.845398</td>\n",
              "      <td>0.239098</td>\n",
              "      <td>0.349138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.849963</td>\n",
              "      <td>0.238172</td>\n",
              "      <td>0.349138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.859708</td>\n",
              "      <td>0.237999</td>\n",
              "      <td>0.344828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.866480</td>\n",
              "      <td>0.236882</td>\n",
              "      <td>0.340517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.862419</td>\n",
              "      <td>0.240032</td>\n",
              "      <td>0.349138</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=160, training_loss=1.5366881370544434, metrics={'train_runtime': 113.4621, 'train_samples_per_second': 2.82, 'train_steps_per_second': 1.41, 'total_flos': 26852007198720.0, 'train_loss': 1.5366881370544434, 'epoch': 10.0})"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "model = AutoAdapterModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "# Load two adapters\n",
        "model.load_adapter(\"la_s\", load_as=\"source_script\")\n",
        "model.load_adapter(\"la_t\", load_as=\"transliterated\")\n",
        "\n",
        "adapter_setup = Fuse(\"source_script\", \"transliterated\")\n",
        "model.add_adapter_fusion(adapter_setup)\n",
        "\n",
        "# POS classification head\n",
        "model.add_tagging_head(\"pos_head\", num_labels=len(id2label))\n",
        "\n",
        "# Activate fusion\n",
        "model.train_adapter_fusion(adapter_setup)\n",
        "\n",
        "#  Training\n",
        "training_args = TrainingArguments(\n",
        "    learning_rate=1e-4,\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=1,\n",
        "    logging_dir=\"./logs\",\n",
        "    output_dir=\"./pos_fusion\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "trainer = AdapterTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=dev_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1PNAL0vYfRW",
        "outputId": "5eecadbc-d501-4e54-ffb7-bc0ac41f55d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('سەن', 'INTJ'), ('شۇ', 'INTJ'), ('چاققىچە', 'INTJ'), ('تاقەت', 'INTJ'), ('قىلىپ', 'INTJ'), ('تۇرالامسەن!', 'PUNCT')]\n",
            "## AdapterFusion Model Evaluation ##\n",
            "F1 score on Dev Data: 0.2400323275862069\n",
            "\n",
            "Class-wise scores:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ADJ      0.000     0.000     0.000        15\n",
            "         ADP      0.000     0.000     0.000         9\n",
            "         ADV      0.000     0.000     0.000         7\n",
            "         AUX      0.000     0.000     0.000         7\n",
            "       CCONJ      0.000     0.000     0.000         4\n",
            "         DET      0.000     0.000     0.000         2\n",
            "        INTJ      0.482     0.920     0.633        88\n",
            "        NOUN      0.000     0.000     0.000         4\n",
            "         NUM      0.000     0.000     0.000        12\n",
            "        PART      0.000     0.000     0.000        39\n",
            "        PRON      0.000     0.000     0.000        45\n",
            "       PROPN      0.000     0.000     0.000         0\n",
            "       PUNCT      0.000     0.000     0.000         0\n",
            "\n",
            "    accuracy                          0.349       232\n",
            "   macro avg      0.037     0.071     0.049       232\n",
            "weighted avg      0.183     0.349     0.240       232\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluation and Prediction\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def predict_pos(sentence):\n",
        "    tokenized = tokenizer(\n",
        "        sentence.split(),\n",
        "        is_split_into_words=True,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**tokenized)\n",
        "\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1).squeeze().tolist()\n",
        "    word_ids = tokenized.word_ids(batch_index=0)\n",
        "\n",
        "    pred_tags = []\n",
        "    current_word = None\n",
        "    for i, word_idx in enumerate(word_ids):\n",
        "        if word_idx != current_word and word_idx is not None:\n",
        "            pred_tags.append(id2label[predictions[i]])\n",
        "            current_word = word_idx\n",
        "\n",
        "    return list(zip(sentence.split(), pred_tags))\n",
        "\n",
        "# test_sentence = \"نەشپۈت بەش يىلدا، ئۆرۈك تۆت يىلدا مېۋە بېرىدۇ دېگەننى ئاڭلىمىغانمىدىڭ؟\"\n",
        "# test_sentence = \"neshpüt besh yilda, örük töt yilda mëwe bëridu dëgenni anglimighanmiding ?\"\n",
        "test_sentence = \"سەن شۇ چاققىچە تاقەت قىلىپ تۇرالامسەن!\"\n",
        "print(predict_pos(test_sentence))\n",
        "\n",
        "# Evaluation Report\n",
        "def get_true_pred(model, dataset):\n",
        "    all_true = []\n",
        "    all_pred = []\n",
        "    model.eval()\n",
        "\n",
        "    for item in dataset:\n",
        "        inputs = {\n",
        "            \"input_ids\": item[\"input_ids\"].unsqueeze(0).to(device),\n",
        "            \"attention_mask\": item[\"attention_mask\"].unsqueeze(0).to(device)\n",
        "        }\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        preds = torch.argmax(outputs.logits, dim=-1).squeeze().cpu().tolist()\n",
        "        labels = item[\"labels\"].tolist()\n",
        "\n",
        "        # mask ignoring -100 labels\n",
        "        mask = [label != -100 for label in labels]\n",
        "        all_true.extend([labels[i] for i, m in enumerate(mask) if m])\n",
        "        all_pred.extend([preds[i] for i, m in enumerate(mask) if m])\n",
        "\n",
        "    return all_true, all_pred\n",
        "\n",
        "# predictions and labels\n",
        "y_true, y_pred = get_true_pred(model, dev_dataset)\n",
        "\n",
        "# classification report\n",
        "print(\"## AdapterFusion Model Evaluation ##\")\n",
        "print(\"F1 score on Dev Data:\", f1_score(y_true, y_pred, average=\"weighted\"))\n",
        "print(\"\\nClass-wise scores:\")\n",
        "print(classification_report(\n",
        "    [id2label[t] for t in y_true],\n",
        "    [id2label[p] for p in y_pred],\n",
        "    digits=3,\n",
        "    zero_division=0\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbMcrRnXJ0YU"
      },
      "source": [
        "# Dependency Parsing AdapterFusionPlus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTNourwlymwG",
        "outputId": "5eb15489-b1d3-43af-d60d-c797bde6f67e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dependency Labels Mapping: {'acl': 0, 'advcl': 1, 'advmod': 2, 'amod': 3, 'appos': 4, 'aux': 5, 'case': 6, 'cc': 7, 'ccomp': 8, 'compound': 9, 'compound:lvc': 10, 'compound:redup': 11, 'conj': 12, 'cop': 13, 'det': 14, 'discourse': 15, 'dislocated': 16, 'flat': 17, 'mark': 18, 'nmod': 19, 'nmod:poss': 20, 'nsubj': 21, 'nummod': 22, 'obj': 23, 'obl': 24, 'obl:tmod': 25, 'orphan': 26, 'parataxis': 27, 'punct': 28, 'root': 29, 'vocative': 30, 'xcomp': 31}\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from transformers import AutoTokenizer, AdamW\n",
        "from adapters import AutoAdapterModel\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class AdapterFusionPlus(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2 * hidden_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, 2)\n",
        "        )\n",
        "    def forward(self, outputs_s, outputs_t):\n",
        "        combined = torch.cat([outputs_s, outputs_t], dim=-1)   # [B, T, 2*H]\n",
        "        raw_weights = self.mlp(combined)                       # [B, T, 2]\n",
        "        weights = torch.softmax(raw_weights, dim=-1)           # [B, T, 2]\n",
        "        w_s = weights[:, :, 0].unsqueeze(-1)                   # [B, T, 1]\n",
        "        w_t = weights[:, :, 1].unsqueeze(-1)                   # [B, T, 1]\n",
        "        fused_output = w_s * outputs_s + w_t * outputs_t       # [B, T, H]\n",
        "        return fused_output\n",
        "\n",
        "def create_dep_label_mapping(file_path):\n",
        "    \"\"\"\n",
        "    Reads a CoNLL-U file and generates a unique mapping for dependency labels.\n",
        "    \"\"\"\n",
        "    dep_labels_set = set()\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            if not line.startswith(\"#\") and line.strip():\n",
        "                parts = line.split(\"\\t\")\n",
        "                if len(parts) == 10:\n",
        "                    dep_labels_set.add(parts[7])\n",
        "    dep_label2id = {label: idx for idx, label in enumerate(sorted(dep_labels_set))}\n",
        "    dep_id2label = {idx: label for label, idx in dep_label2id.items()}\n",
        "    return dep_label2id, dep_id2label\n",
        "\n",
        "conllu_pth = \"ug_udt-ud-train.conllu\"\n",
        "file_path = conllu_pth\n",
        "dep_label2id, dep_id2label = create_dep_label_mapping(file_path)\n",
        "NUM_DEP_LABELS = len(dep_label2id)\n",
        "print(f\"Dependency Labels Mapping: {dep_label2id}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ANV9ON6vclOb"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ConlluDataset(Dataset):\n",
        "    def __init__(self, file_path, tokenizer, dep_label2id, max_length=128):\n",
        "        self.sentences = self.load_conllu(file_path, dep_label2id)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def load_conllu(self, file_path, dep_label2id):\n",
        "\n",
        "        sentences = []\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            sentence = []\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if line == \"\":\n",
        "                    if sentence:\n",
        "                        sentences.append(sentence)\n",
        "                        sentence = []\n",
        "                elif not line.startswith(\"#\"):\n",
        "                    parts = line.split(\"\\t\")\n",
        "                    if len(parts) == 10:\n",
        "                        token_id, token, lemma, upos, xpos, feats, head, dep_rel, deps, misc = parts\n",
        "                        label = dep_label2id.get(dep_rel, -1)\n",
        "                        sentence.append((token, upos, int(head), label))\n",
        "            if sentence:\n",
        "                sentences.append(sentence)\n",
        "        return sentences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = self.sentences[idx]\n",
        "        tokens = [word[0] for word in sentence]\n",
        "        dep_heads = [word[2] for word in sentence]\n",
        "        dep_labels = [word[3] for word in sentence]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            tokens,\n",
        "            is_split_into_words=True,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "            max_length=self.max_length,\n",
        "            return_offsets_mapping=True\n",
        "        )\n",
        "        word_starts = torch.zeros(len(encoding[\"input_ids\"][0]), dtype=torch.long)\n",
        "        word_ids = encoding.word_ids()\n",
        "        for i, word_idx in enumerate(word_ids):\n",
        "            if word_idx is not None and (i == 0 or word_ids[i-1] != word_idx):\n",
        "                word_starts[i] = 1\n",
        "\n",
        "        padded_dep_labels = torch.full((self.max_length,), -1, dtype=torch.long)\n",
        "        padded_dep_heads = torch.full((self.max_length,), -1, dtype=torch.long)\n",
        "        seq_len = len(dep_labels)\n",
        "        padded_dep_labels[:seq_len] = torch.tensor(dep_labels, dtype=torch.long)\n",
        "        padded_dep_heads[:seq_len] = torch.tensor(dep_heads, dtype=torch.long)\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"dep_heads\": padded_dep_heads,\n",
        "            \"dep_labels\": padded_dep_labels,\n",
        "            \"word_starts\": word_starts       # shape: [max_length]\n",
        "        }\n",
        "\n",
        "def collate_fn(batch):\n",
        "    input_ids = torch.stack([item['input_ids'] for item in batch])\n",
        "    attention_mask = torch.stack([item['attention_mask'] for item in batch])\n",
        "    dep_heads = torch.stack([item['dep_heads'] for item in batch])\n",
        "    dep_labels = torch.stack([item['dep_labels'] for item in batch])\n",
        "    word_starts = torch.stack([item['word_starts'] for item in batch])\n",
        "    return {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_mask\": attention_mask,\n",
        "        \"dep_heads\": dep_heads,\n",
        "        \"dep_labels\": dep_labels,\n",
        "        \"word_starts\": word_starts\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue7dGTb89Svl",
        "outputId": "b3568484-65c1-4f8c-9cdb-d6d447486eb3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertAdapterModel were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['heads.default.3.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "base_model = AutoAdapterModel.from_pretrained(\"bert-base-multilingual-cased\").to(device)\n",
        "base_model.load_adapter(\"la_s\")\n",
        "base_model.load_adapter(\"la_t\")\n",
        "\n",
        "class DependencyParser(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size, num_labels):\n",
        "        super().__init__()\n",
        "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
        "    def forward(self, fused_output):\n",
        "        return self.classifier(fused_output)\n",
        "\n",
        "class DependencyParserFusionModel(nn.Module):\n",
        "\n",
        "    def __init__(self, base_model, fusion_layer, classifier):\n",
        "        super().__init__()\n",
        "        self.base_model = base_model\n",
        "        self.fusion_layer = fusion_layer\n",
        "        self.classifier = classifier\n",
        "        self.base_model.config.output_hidden_states = True\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Activate and get outputs from the first adapter\n",
        "        self.base_model.set_active_adapters([\"la_s\"])\n",
        "        outputs_s = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Activate and get outputs from the second adapter\n",
        "        self.base_model.set_active_adapters([\"la_t\"])\n",
        "        outputs_t = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Fuse the outputs from both adapters\n",
        "        fused = self.fusion_layer(outputs_s.hidden_states[-1], outputs_t.hidden_states[-1])\n",
        "        # classification logits: shape [B, seq_len, NUM_DEP_LABELS]\n",
        "        return self.classifier(fused)\n",
        "\n",
        "fusion_layer = AdapterFusionPlus(base_model.config.hidden_size).to(device)\n",
        "dependency_parser_classifier = DependencyParser(base_model.config.hidden_size, NUM_DEP_LABELS).to(device)\n",
        "DepPar_model = DependencyParserFusionModel(base_model, fusion_layer, dependency_parser_classifier).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGscJQcMpaJx",
        "outputId": "5b735c29-0b67-4af5-9bf8-01892f724699"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 - Loss: 2.4748\n",
            "Epoch 2/10 - Loss: 2.1343\n",
            "Epoch 3/10 - Loss: 1.8472\n",
            "Epoch 4/10 - Loss: 1.5950\n",
            "Epoch 5/10 - Loss: 1.2657\n",
            "Epoch 6/10 - Loss: 1.0588\n",
            "Epoch 7/10 - Loss: 0.9096\n",
            "Epoch 8/10 - Loss: 0.9226\n",
            "Epoch 9/10 - Loss: 0.5313\n",
            "Epoch 10/10 - Loss: 1.0226\n",
            "Dependency Parser LAS: 0.1076\n"
          ]
        }
      ],
      "source": [
        "def train_DepPar_model(model, dataloader, num_epochs=3, lr=1e-4):\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for batch in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"dep_labels\"].to(device)\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            loss = criterion(logits.view(-1, logits.shape[-1]), labels.view(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {total_loss / len(dataloader):.4f}\")\n",
        "\n",
        "def evaluate_DepPar_model(model, dataloader):\n",
        "    model.eval()\n",
        "    total_correct, total_tokens = 0, 0\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"dep_labels\"].to(device)\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            predictions = torch.argmax(logits, dim=-1)\n",
        "            mask = labels != -1\n",
        "            correct = (predictions == labels) & mask\n",
        "            total_correct += correct.sum().item()\n",
        "            total_tokens += mask.sum().item()\n",
        "            y_true.extend(labels[mask].cpu().tolist())\n",
        "            y_pred.extend(predictions[mask].cpu().tolist())\n",
        "    las = total_correct / total_tokens if total_tokens > 0 else 0\n",
        "    print(f\"Dependency Parser LAS: {las:.4f}\")\n",
        "    return y_true, y_pred\n",
        "\n",
        "train_dataset = ConlluDataset(conllu_pth, tokenizer, dep_label2id)\n",
        "val_dataset = ConlluDataset(\"ug_udt-ud-test.conllu\", tokenizer, dep_label2id)\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "train_DepPar_model(DepPar_model, train_loader, num_epochs=10)\n",
        "_ = evaluate_DepPar_model(DepPar_model, val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zbWCxCyU58E",
        "outputId": "761f0064-8a65-4853-c1bc-6ece01176ca8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dependency Parsing Result:\n",
            "OrigToken\tParsedToken\tPredicted Head\tDependency Label\n",
            "نەشپۈت\t\tنەشپۈت\t\tROOT\t\t\tnummod\n",
            "بەش\t\tبەش\t\tنەشپۈت\t\t\tpunct\n",
            "يىلدا،\t\tيىلدا،\t\tبەش\t\t\tpunct\n",
            "ئۆرۈك\t\tئۆرۈك\t\tيىلدا،\t\t\tconj\n",
            "تۆت\t\tتۆت\t\tئۆرۈك\t\t\tobj\n",
            "يىلدا\t\tيىلدا\t\tتۆت\t\t\tpunct\n",
            "مېۋە\t\tمېۋە\t\tيىلدا\t\t\tpunct\n",
            "بېرىدۇ\t\tبېرىدۇ\t\tمېۋە\t\t\tpunct\n",
            "دېگەننى\t\tدېگەننى\t\tبېرىدۇ\t\t\tpunct\n",
            "ئاڭلىمىغانمىدىڭ\t\tئاڭلىمىغانمىدىڭ\t\tدېگەننى\t\t\tcompound:redup\n",
            "؟\t\t؟\t\tئاڭلىمىغانمىدىڭ\t\t\tparataxis\n"
          ]
        }
      ],
      "source": [
        "def parse_sentence_dep_fusion(model, tokenizer, sentence, dep_id2label, max_length=128):\n",
        "\n",
        "    original_tokens = sentence.strip().split()\n",
        "\n",
        "    encoding = tokenizer(\n",
        "        original_tokens,\n",
        "        is_split_into_words=True,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\",\n",
        "        max_length=max_length,\n",
        "        return_offsets_mapping=True\n",
        "    )\n",
        "\n",
        "    word_ids = encoding.word_ids(0)\n",
        "    word_starts = torch.zeros(len(encoding[\"input_ids\"][0]), dtype=torch.long)\n",
        "    model_words = []\n",
        "    previous_word_idx = None\n",
        "    for pos, word_idx in enumerate(word_ids):\n",
        "        if word_idx is None:\n",
        "            continue\n",
        "        if word_idx != previous_word_idx:\n",
        "            word_starts[pos] = 1\n",
        "            model_words.append(original_tokens[word_idx])\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "    word_starts = word_starts.unsqueeze(0)\n",
        "    input_ids = encoding[\"input_ids\"].to(device)\n",
        "    attention_mask = encoding[\"attention_mask\"].to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_ids, attention_mask)  # shape: [1, seq_len, NUM_DEP_LABELS]\n",
        "        predictions = torch.argmax(logits, dim=-1).squeeze(0).cpu().tolist()\n",
        "\n",
        "    word_pred_labels = []\n",
        "    for pos, word_idx in enumerate(word_ids):\n",
        "        if word_idx is None:\n",
        "            continue\n",
        "        if pos == 0 or (word_ids[pos - 1] != word_idx):\n",
        "            word_pred_labels.append(predictions[pos])\n",
        "\n",
        "    simulated_heads = []\n",
        "    for i in range(len(model_words)):\n",
        "        if i == 0:\n",
        "            simulated_heads.append(\"ROOT\")\n",
        "        else:\n",
        "            simulated_heads.append(model_words[i - 1])\n",
        "\n",
        "    print(\"Dependency Parsing Result:\")\n",
        "    print(\"OrigToken\\tParsedToken\\tPredicted Head\\tDependency Label\")\n",
        "    for i in range(len(model_words)):\n",
        "        token = original_tokens[i] if i < len(original_tokens) else \"UNK\"\n",
        "        parsed_token = model_words[i]\n",
        "        pred_label = dep_id2label.get(word_pred_labels[i], \"UNKNOWN\")\n",
        "        pred_head = simulated_heads[i]\n",
        "        print(f\"{token}\\t\\t{parsed_token}\\t\\t{pred_head}\\t\\t\\t{pred_label}\")\n",
        "\n",
        "test_sentence = \"نەشپۈت بەش يىلدا، ئۆرۈك تۆت يىلدا مېۋە بېرىدۇ دېگەننى ئاڭلىمىغانمىدىڭ ؟\"\n",
        "parse_sentence_dep_fusion(DepPar_model, tokenizer, test_sentence, dep_id2label)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65wSNa6py0Xu"
      },
      "source": [
        "# Dependency Parsing AdapterFusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        },
        "id": "0IlO1SwsJC5d",
        "outputId": "39b18e0c-fde4-4774-c851-110c86bd9acb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial Dependency Labels Mapping: {'acl': 0, 'advcl': 1, 'advmod': 2, 'amod': 3, 'ccomp': 4, 'compound': 5, 'conj': 6, 'cop': 7, 'det': 8, 'discourse': 9, 'dislocated': 10, 'flat': 11, 'nmod': 12, 'nsubj': 13, 'nummod': 14, 'obj': 15, 'obl': 16, 'orphan': 17, 'parataxis': 18, 'punct': 19, 'root': 20, 'vocative': 21, 'xcomp': 22}\n",
            "All labels in training set: {'nmod:poss', 'nsubj', 'parataxis', 'discourse', 'cop', 'conj', 'advmod', 'dislocated', 'det', 'case', 'mark', 'vocative', 'flat', 'obl', 'orphan', 'punct', 'obl:tmod', 'cc', 'xcomp', 'aux', 'compound:redup', 'ccomp', 'nummod', 'nmod', 'obj', 'amod', 'root', 'acl', 'compound:lvc', 'advcl', 'appos', 'compound'}\n",
            "Updated Dependency Labels Mapping: {'acl': 0, 'advcl': 1, 'advmod': 2, 'amod': 3, 'ccomp': 4, 'compound': 5, 'conj': 6, 'cop': 7, 'det': 8, 'discourse': 9, 'dislocated': 10, 'flat': 11, 'nmod': 12, 'nsubj': 13, 'nummod': 14, 'obj': 15, 'obl': 16, 'orphan': 17, 'parataxis': 18, 'punct': 19, 'root': 20, 'vocative': 21, 'xcomp': 22, 'nmod:poss': 23, 'case': 24, 'mark': 25, 'obl:tmod': 26, 'cc': 27, 'aux': 28, 'compound:redup': 29, 'compound:lvc': 30, 'appos': 31}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertAdapterModel were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['heads.default.3.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [160/160 02:13, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.132030</td>\n",
              "      <td>0.052066</td>\n",
              "      <td>0.174888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.087168</td>\n",
              "      <td>0.052066</td>\n",
              "      <td>0.174888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.068566</td>\n",
              "      <td>0.052066</td>\n",
              "      <td>0.174888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.073404</td>\n",
              "      <td>0.052066</td>\n",
              "      <td>0.174888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.077580</td>\n",
              "      <td>0.052265</td>\n",
              "      <td>0.174888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.086957</td>\n",
              "      <td>0.052066</td>\n",
              "      <td>0.174888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.082647</td>\n",
              "      <td>0.052066</td>\n",
              "      <td>0.174888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.082368</td>\n",
              "      <td>0.052265</td>\n",
              "      <td>0.174888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.084063</td>\n",
              "      <td>0.052265</td>\n",
              "      <td>0.174888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.083540</td>\n",
              "      <td>0.052466</td>\n",
              "      <td>0.174888</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=160, training_loss=2.726246643066406, metrics={'train_runtime': 133.7486, 'train_samples_per_second': 2.393, 'train_steps_per_second': 1.196, 'total_flos': 26855409008640.0, 'train_loss': 2.726246643066406, 'epoch': 10.0})"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from adapters.composition import Fuse\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def create_dep_label_mapping(file_path):\n",
        "    mapping = {\n",
        "        'acl': 0, 'advcl': 1, 'advmod': 2, 'amod': 3, 'ccomp': 4,\n",
        "        'compound': 5, 'conj': 6, 'cop': 7, 'det': 8, 'discourse': 9,\n",
        "        'dislocated': 10, 'flat': 11, 'nmod': 12, 'nsubj': 13, 'nummod': 14,\n",
        "        'obj': 15, 'obl': 16, 'orphan': 17, 'parataxis': 18, 'punct': 19,\n",
        "        'root': 20, 'vocative': 21, 'xcomp': 22\n",
        "    }\n",
        "    id2label = {v: k for k, v in mapping.items()}\n",
        "    return mapping, id2label\n",
        "\n",
        "def load_conllu_data(path, head_offset=64):\n",
        "    data = []\n",
        "    with open(path, encoding=\"utf-8\") as f:\n",
        "        lines = f.read().strip().split(\"\\n\")\n",
        "    sentence_lines = []\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":\n",
        "            if sentence_lines:\n",
        "                data.append(parse_sentence(sentence_lines, head_offset))\n",
        "                sentence_lines = []\n",
        "        else:\n",
        "            sentence_lines.append(line)\n",
        "    if sentence_lines:\n",
        "        data.append(parse_sentence(sentence_lines, head_offset))\n",
        "    return data\n",
        "\n",
        "def parse_sentence(lines, head_offset):\n",
        "    sent_text = None\n",
        "    tokens = []\n",
        "    dep_heads = []\n",
        "    dep_labels = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.startswith(\"# text =\"):\n",
        "            sent_text = line[len(\"# text =\"):].strip()\n",
        "            break\n",
        "    for line in lines:\n",
        "        if line.startswith(\"#\"):\n",
        "            continue\n",
        "        parts = line.split(\"\\t\")\n",
        "        if len(parts) < 8:\n",
        "            continue\n",
        "        if \"-\" in parts[0]:\n",
        "            continue\n",
        "        tokens.append(parts[1])\n",
        "        head = int(parts[6])\n",
        "        dep_heads.append(head)\n",
        "        dep_labels.append(parts[7])\n",
        "    if sent_text is None:\n",
        "        sent_text = \" \".join(tokens)\n",
        "    return {\n",
        "        \"sentence\": sent_text,\n",
        "        \"dep_heads\": dep_heads,\n",
        "        \"dep_labels\": dep_labels,\n",
        "        \"tokens\": tokens\n",
        "    }\n",
        "\n",
        "class ConlluDataset(Dataset):\n",
        "    def __init__(self, file_path, tokenizer, dep_label2id):\n",
        "        self.data = load_conllu_data(file_path)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.dep_label2id = dep_label2id\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    def __getitem__(self, idx):\n",
        "        example = self.data[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            example[\"sentence\"].split(),\n",
        "            is_split_into_words=True,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=128\n",
        "        )\n",
        "        label_ids = [self.dep_label2id.get(label, -100) for label in example[\"dep_labels\"]]\n",
        "\n",
        "        max_length = encoding[\"input_ids\"].shape[-1]\n",
        "        label_tensor = torch.full((max_length,), -100, dtype=torch.long)\n",
        "        label_tensor[:len(label_ids)] = torch.tensor(label_ids, dtype=torch.long)\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": label_tensor\n",
        "        }\n",
        "\n",
        "conllu_pth = \"ug_udt-ud-train.conllu\"\n",
        "dev_conllu   = \"ug_udt-ud-test.conllu\"\n",
        "\n",
        "# dependency label mapping.\n",
        "dep_label2id, dep_id2label = create_dep_label_mapping(conllu_pth)\n",
        "print(f\"Initial Dependency Labels Mapping: {dep_label2id}\")\n",
        "\n",
        "# tokenizer and create datasets.\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "train_dataset = ConlluDataset(conllu_pth, tokenizer, dep_label2id)\n",
        "val_dataset = ConlluDataset(dev_conllu, tokenizer, dep_label2id)\n",
        "\n",
        "all_train_labels = set()\n",
        "for example in train_dataset.data:\n",
        "    for label in example[\"dep_labels\"]:\n",
        "        all_train_labels.add(label)\n",
        "print(\"All labels in training set:\", all_train_labels)\n",
        "\n",
        "for label in all_train_labels:\n",
        "    if label not in dep_label2id:\n",
        "        dep_label2id[label] = len(dep_label2id)\n",
        "dep_id2label = {v: k for k, v in dep_label2id.items()}\n",
        "NUM_DEP_LABELS = len(dep_label2id)\n",
        "print(\"Updated Dependency Labels Mapping:\", dep_label2id)\n",
        "\n",
        "# compute_metrics.\n",
        "def compute_metrics(p):\n",
        "    predictions = np.argmax(p.predictions, axis=2)\n",
        "    true_labels = p.label_ids  \n",
        "    mask = true_labels != -100  \n",
        "    y_true = true_labels[mask].flatten()\n",
        "    y_pred = predictions[mask].flatten()\n",
        "    return {\n",
        "        \"f1\": f1_score(y_true, y_pred, average=\"weighted\"),\n",
        "        \"accuracy\": accuracy_score(y_true, y_pred)\n",
        "    }\n",
        "\n",
        "\n",
        "model = AutoAdapterModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "# add adapters.\n",
        "model.load_adapter(\"la_s\", load_as=\"source_script\")\n",
        "model.load_adapter(\"la_t\", load_as=\"transliterated\")\n",
        "# add adapter fusion.\n",
        "adapter_setup = Fuse(\"source_script\", \"transliterated\")\n",
        "model.add_adapter_fusion(adapter_setup)\n",
        "# Add dependency tagging head.\n",
        "model.add_tagging_head(\"dep_head\", num_labels=NUM_DEP_LABELS)\n",
        "# Activate fusion and the tagging head.\n",
        "model.train_adapter_fusion(adapter_setup)\n",
        "model.set_active_adapters(adapter_setup)\n",
        "if hasattr(model, \"set_active_head\"):\n",
        "    model.set_active_head(\"dep_head\")\n",
        "else:\n",
        "    model.active_head = \"dep_head\"\n",
        "\n",
        "def collate_fn(batch):\n",
        "    input_ids = torch.stack([item[\"input_ids\"] for item in batch])\n",
        "    attention_mask = torch.stack([item[\"attention_mask\"] for item in batch])\n",
        "    labels = torch.stack([item[\"labels\"] for item in batch])\n",
        "    return {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_mask\": attention_mask,\n",
        "        \"labels\": labels\n",
        "    }\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    learning_rate=1e-4,\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=1,\n",
        "    logging_dir=\"./logs\",\n",
        "    output_dir=\"./dep_fusion\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "trainer = AdapterTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    data_collator=collate_fn,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk2p_nQNWb7o",
        "outputId": "e4fce8d9-e965-4b48-cc37-c94039120aea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dependency Parsing Result:\n",
            "OrigToken\t\tParsedToken\t\tPredicted Head\t\tDependency Label\n",
            "نەشپۈت\t\tنەشپۈت\t\tROOT\t\tpunct\n",
            "بەش\t\tبەش\t\tنەشپۈت\t\tpunct\n",
            "يىلدا،\t\tيىلدا،\t\tبەش\t\tpunct\n",
            "ئۆرۈك\t\tئۆرۈك\t\tيىلدا،\t\tpunct\n",
            "تۆت\t\tتۆت\t\tئۆرۈك\t\tpunct\n",
            "يىلدا\t\tيىلدا\t\tتۆت\t\tpunct\n",
            "مېۋە\t\tمېۋە\t\tيىلدا\t\tpunct\n",
            "بېرىدۇ\t\tبېرىدۇ\t\tمېۋە\t\tpunct\n",
            "دېگەننى\t\tدېگەننى\t\tبېرىدۇ\t\tpunct\n",
            "ئاڭلىمىغانمىدىڭ\t\tئاڭلىمىغانمىدىڭ\t\tدېگەننى\t\tpunct\n",
            "؟\t\t؟\t\tئاڭلىمىغانمىدىڭ\t\tpunct\n"
          ]
        }
      ],
      "source": [
        "def infer_dependency_parsing(sentence, tokenizer, model, dep_id2label, max_length=128):\n",
        "    encoding = tokenizer(\n",
        "        sentence.split(),\n",
        "        is_split_into_words=True,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=max_length\n",
        "    )\n",
        "    input_ids = encoding[\"input_ids\"].to(model.device)\n",
        "    attention_mask = encoding[\"attention_mask\"].to(model.device)\n",
        "\n",
        "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1)[0]\n",
        "\n",
        "    word_ids = encoding.word_ids()\n",
        "    predicted_labels = {}\n",
        "    previous_word_idx = None\n",
        "    for idx, word_idx in enumerate(word_ids):\n",
        "        if word_idx is None:\n",
        "            continue\n",
        "        if word_idx != previous_word_idx:\n",
        "            label_id = predictions[idx].item()\n",
        "            predicted_labels[word_idx] = dep_id2label.get(label_id, \"UNK\")\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "    words = sentence.split()\n",
        "    results = []\n",
        "    for i, word in enumerate(words):\n",
        "        orig_token = word\n",
        "        parsed_token = word\n",
        "        pred_head = \"ROOT\" if i == 0 else words[i-1]\n",
        "        dep_label = predicted_labels.get(i, \"UNK\")\n",
        "        results.append((orig_token, parsed_token, pred_head, dep_label))\n",
        "    return results\n",
        "\n",
        "sample_sentence = \"نەشپۈت بەش يىلدا، ئۆرۈك تۆت يىلدا مېۋە بېرىدۇ دېگەننى ئاڭلىمىغانمىدىڭ ؟\"\n",
        "results = infer_dependency_parsing(sample_sentence, tokenizer, model, dep_id2label)\n",
        "\n",
        "print(\"Dependency Parsing Result:\")\n",
        "print(\"OrigToken\\t\\tParsedToken\\t\\tPredicted Head\\t\\tDependency Label\")\n",
        "for orig, parsed, head, label in results:\n",
        "    print(f\"{orig}\\t\\t{parsed}\\t\\t{head}\\t\\t{label}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgiyKfOc8KLU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04433ca5233b4afcb8686c1c92deece2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0fc16461a7e44d9ba9e87c4926165e4",
            "placeholder": "​",
            "style": "IPY_MODEL_7334fec0235545c5a49f313c78cd54ce",
            "value": " 996k/996k [00:00&lt;00:00, 6.77MB/s]"
          }
        },
        "09cdbee747ca4a198a7031ceb8c917f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ef616e2d52e48fb8419dbccdc3d6233": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_469df34bf36d426abde83800fdd12875",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4789d4732f049f8854a3ee22d948836",
            "value": 995526
          }
        },
        "10f8fe170f314e1188bc6471eb57b8bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a4bb2c05be54718a3f1c2501da635c5",
            "placeholder": "​",
            "style": "IPY_MODEL_1bc9b3aa5b8b48a886a6394b55424b17",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 6.69MB/s]"
          }
        },
        "11563d3343ec4fe58b22ff40b0509fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "11bd99d32d99461682384dfe96cfe949": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e50b475a5f904497b0dae6acf50b4ef2",
              "IPY_MODEL_0ef616e2d52e48fb8419dbccdc3d6233",
              "IPY_MODEL_04433ca5233b4afcb8686c1c92deece2"
            ],
            "layout": "IPY_MODEL_4125cdd5a52e40d392b1c802b899793c"
          }
        },
        "127e7d98320e4f5689887020b9cf59f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12d2e85472214abda9173fe7aa06e1e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1644973841d14e5ba0de6fc82ff5263d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bc9b3aa5b8b48a886a6394b55424b17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1efefc5bbd154c33875c76f7ccad6118": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "204139dc12fd4e6fa2a12e8b0747df99": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32a88a7cc44440898741371030fb81e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "379abd0b5d274817a9f08f8583b106e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71e431dbdfcd45c6810277eb0e2bfe43",
              "IPY_MODEL_9f87ac40a8b042f48ae873176ee6052e",
              "IPY_MODEL_10f8fe170f314e1188bc6471eb57b8bf"
            ],
            "layout": "IPY_MODEL_127e7d98320e4f5689887020b9cf59f2"
          }
        },
        "3a316ceac9c14cb79e2a05323e9a77cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c95366915ee4dae97ff6aecd472a4f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4026c33ee5234cba8b807ab18f49cd37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9db173de3bbd408a8061ec9a6a14ff37",
            "max": 714290682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eaa9e4898dc147deb3924097d73a478d",
            "value": 714290682
          }
        },
        "4125cdd5a52e40d392b1c802b899793c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42ffef1c28d446a8a5b97c31e5bded5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "469df34bf36d426abde83800fdd12875": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47feb55d00304294a299114167a94359": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "481da10d40834609aaff9729d6a238cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cadf26b364424441adf92e52550ddd6a",
              "IPY_MODEL_4026c33ee5234cba8b807ab18f49cd37",
              "IPY_MODEL_7180d8c8834e4ead9038b912f2c89c78"
            ],
            "layout": "IPY_MODEL_3a316ceac9c14cb79e2a05323e9a77cd"
          }
        },
        "4f6761d176c4474a87c96f1dbeb6bdd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56a6c7a79329445db76c5e03e06f3e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32a88a7cc44440898741371030fb81e3",
            "placeholder": "​",
            "style": "IPY_MODEL_4f6761d176c4474a87c96f1dbeb6bdd0",
            "value": "config.json: 100%"
          }
        },
        "63ce9ac113ab41c6b414a5536e559513": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68adacb36aa64fee877e3e7dc5585567": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8947613023ff417e9eb3a3ca85de3273",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11563d3343ec4fe58b22ff40b0509fb9",
            "value": 625
          }
        },
        "701b2e2c4adf4dd0974d22f4413341c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "709fb2fb7a654422b12d1cb7409bd353": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "712c8d57806843c086b9c0ba433a5ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_701b2e2c4adf4dd0974d22f4413341c8",
            "placeholder": "​",
            "style": "IPY_MODEL_dbc6b2e2c25a4c219a06c378bd8fec16",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "7180d8c8834e4ead9038b912f2c89c78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_204139dc12fd4e6fa2a12e8b0747df99",
            "placeholder": "​",
            "style": "IPY_MODEL_b36a988efe2e496fa0355dd809993764",
            "value": " 714M/714M [00:08&lt;00:00, 235MB/s]"
          }
        },
        "71e431dbdfcd45c6810277eb0e2bfe43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12d2e85472214abda9173fe7aa06e1e5",
            "placeholder": "​",
            "style": "IPY_MODEL_63ce9ac113ab41c6b414a5536e559513",
            "value": "tokenizer.json: 100%"
          }
        },
        "7334fec0235545c5a49f313c78cd54ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8380346e5b844ce199917f7f47178ba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_709fb2fb7a654422b12d1cb7409bd353",
            "placeholder": "​",
            "style": "IPY_MODEL_c1b9be3b4e014d1dabfb3c3d08f937e5",
            "value": " 625/625 [00:00&lt;00:00, 62.5kB/s]"
          }
        },
        "85285f8ab6c147c8a6e4a3293a501122": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8947613023ff417e9eb3a3ca85de3273": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a4bb2c05be54718a3f1c2501da635c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bc20a0d3c694db6b86231098d473146": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ff8f1f41ee74e968acc2d205a6f2a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1efefc5bbd154c33875c76f7ccad6118",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b289b3eab3be46e2888b52f34438d5e6",
            "value": 49
          }
        },
        "917404a8d9044bd2bc3ed8c78ca3f69d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_712c8d57806843c086b9c0ba433a5ee3",
              "IPY_MODEL_8ff8f1f41ee74e968acc2d205a6f2a68",
              "IPY_MODEL_e35543d225854ac3a2676d7a23677a19"
            ],
            "layout": "IPY_MODEL_c566fb0af9d84f309b3ca831c1b92d46"
          }
        },
        "9db173de3bbd408a8061ec9a6a14ff37": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f87ac40a8b042f48ae873176ee6052e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6bef212c6e3450da477130902ef1030",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e638cfc18f1d4ca7bc452070b552861a",
            "value": 1961828
          }
        },
        "a0fc16461a7e44d9ba9e87c4926165e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acffc7a9b4254e62b22628a323178d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56a6c7a79329445db76c5e03e06f3e89",
              "IPY_MODEL_68adacb36aa64fee877e3e7dc5585567",
              "IPY_MODEL_8380346e5b844ce199917f7f47178ba8"
            ],
            "layout": "IPY_MODEL_09cdbee747ca4a198a7031ceb8c917f4"
          }
        },
        "b289b3eab3be46e2888b52f34438d5e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b36a988efe2e496fa0355dd809993764": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1b9be3b4e014d1dabfb3c3d08f937e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c566fb0af9d84f309b3ca831c1b92d46": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cadf26b364424441adf92e52550ddd6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c95366915ee4dae97ff6aecd472a4f7",
            "placeholder": "​",
            "style": "IPY_MODEL_85285f8ab6c147c8a6e4a3293a501122",
            "value": "model.safetensors: 100%"
          }
        },
        "d6bef212c6e3450da477130902ef1030": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbc6b2e2c25a4c219a06c378bd8fec16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e35543d225854ac3a2676d7a23677a19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1644973841d14e5ba0de6fc82ff5263d",
            "placeholder": "​",
            "style": "IPY_MODEL_47feb55d00304294a299114167a94359",
            "value": " 49.0/49.0 [00:00&lt;00:00, 4.80kB/s]"
          }
        },
        "e4789d4732f049f8854a3ee22d948836": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e50b475a5f904497b0dae6acf50b4ef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bc20a0d3c694db6b86231098d473146",
            "placeholder": "​",
            "style": "IPY_MODEL_42ffef1c28d446a8a5b97c31e5bded5e",
            "value": "vocab.txt: 100%"
          }
        },
        "e638cfc18f1d4ca7bc452070b552861a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eaa9e4898dc147deb3924097d73a478d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
